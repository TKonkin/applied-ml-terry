{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf7acad",
   "metadata": {},
   "source": [
    "# Lab 5: Ensemble Machine Learning - Wine Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b0893",
   "metadata": {},
   "source": [
    "Name: Terry Konkin  \n",
    "Date: April 13, 2025  \n",
    "Objective: To compare 2 Ensemble models on the Wine Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a04d60",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4032cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3751e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2da4433",
   "metadata": {},
   "source": [
    "### Section 1. Load and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52997088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset (download from UCI and save in the same folder)\n",
    "df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# Display structure and first few rows\n",
    "df.info()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3a805",
   "metadata": {},
   "source": [
    "The dataset includes 11 physicochemical input variables (features):\n",
    " ---------------------------------------------------------------\n",
    " - fixed acidity -           mostly tartaric acid\n",
    " - volatile acidity -        mostly acetic acid (vinegar)\n",
    " - citric acid -             can add freshness and flavor\n",
    " - residual sugar -          remaining sugar after fermentation\n",
    " - chlorides -               salt content\n",
    " - free sulfur dioxide -     protects wine from microbes\n",
    " - total sulfur dioxide -    sum of free and bound forms\n",
    " - density -                 related to sugar content\n",
    " - pH -                      acidity level (lower = more acidic)\n",
    " - sulphates -               antioxidant and microbial stabilizer\n",
    " - alcohol -                 % alcohol by volume\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627316fe",
   "metadata": {},
   "source": [
    "The target variable is:\n",
    " - quality (integer score from 0 to 10, rated by wine tasters)  \n",
    "  \n",
    "We will simplify this target into three categories:\n",
    "   - low (3–4), medium (5–6), high (7–8) to make classification feasible.  \n",
    "   - we will also make this numeric (we want both for clarity)  \n",
    "The dataset contains 1599 samples and 12 columns (11 features + target)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9145503",
   "metadata": {},
   "source": [
    "### Section 2. Prepare the Data  \n",
    "  \n",
    "Includes cleaning, feature engineering, encoding, splitting, helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d0e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function that:\n",
    "\n",
    "# Takes one input, the quality (which we will temporarily name q while in the function)\n",
    "# And returns a string of the quality label (low, medium, high)\n",
    "# This function will be used to create the quality_label column\n",
    "\n",
    "def quality_to_label(q):\n",
    "    if q <= 4:\n",
    "        return \"low\"\n",
    "    elif q <= 6:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "# Call the apply() method on the quality column to create the new quality_label column\n",
    "df[\"quality_label\"] = df[\"quality\"].apply(quality_to_label)     \n",
    "\n",
    "# Then, create a numeric column for modeling: 0 = low, 1 = medium, 2 = high\n",
    "def quality_to_number(q):\n",
    "    if q <= 4:\n",
    "        return 0\n",
    "    elif q <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df[\"quality_numeric\"] = df[\"quality\"].apply(quality_to_number)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb8c168",
   "metadata": {},
   "source": [
    "### Section 3. Feature Selection and Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5e488e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input features (X) and target (y)\n",
    "# Features: all columns except 'quality' and 'quality_label' and 'quality_numeric' - drop these from the input array\n",
    "# Target: quality_label (the new column we just created)\n",
    "\n",
    "X = df.drop(columns=[\"quality\", \"quality_label\", \"quality_numeric\"])  # Features\n",
    "y = df[\"quality_numeric\"]  # Target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb10df76",
   "metadata": {},
   "source": [
    "Summary:  \n",
    "\n",
    "The input features (X) are all columns in the original dataset with the exception of 'quality'.  \n",
    "The target (y) is the newly created feature 'quality_numeric'.  This column aggregates the quality ratings into 3 categories:  \n",
    "0 (low), 1 (medium), and 2 (high)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc960e39",
   "metadata": {},
   "source": [
    "### Section 4. Split the Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5259c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (stratify to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a1a666",
   "metadata": {},
   "source": [
    "### Section 5. Evaluate Model Performance (Choose 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704f6f77",
   "metadata": {},
   "source": [
    "Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f862ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to train and evaluate models\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\") \n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"Train Accuracy\": train_acc,\n",
    "            \"Test Accuracy\": test_acc,\n",
    "            \"Train F1\": train_f1,\n",
    "            \"Test F1\": test_f1,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea528d",
   "metadata": {},
   "source": [
    "Option 1: Random Forest (100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79393ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 256   8]\n",
      " [  0  15  28]]\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.8875\n",
      "Train F1 Score: 1.0000, Test F1 Score: 0.8661\n"
     ]
    }
   ],
   "source": [
    "# Call the function for Random Forest (100)\n",
    "\n",
    "\n",
    "evaluate_model(\n",
    "    \"Random Forest (100)\",\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22894e44",
   "metadata": {},
   "source": [
    "Option 3: AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca2c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoost (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  1  12   0]\n",
      " [  5 240  19]\n",
      " [  0  20  23]]\n",
      "Train Accuracy: 0.8342, Test Accuracy: 0.8250\n",
      "Train F1 Score: 0.8209, Test F1 Score: 0.8158\n"
     ]
    }
   ],
   "source": [
    "# Call the function for AdaBoost\n",
    "\n",
    "\n",
    "evaluate_model(\n",
    "    \"AdaBoost (100)\",\n",
    "    AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a618e8",
   "metadata": {},
   "source": [
    "### Section 6. Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61218ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of All Models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest (100)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost (100)</td>\n",
       "      <td>0.834246</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.820863</td>\n",
       "      <td>0.815803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train Accuracy  Test Accuracy  Train F1   Test F1\n",
       "0  Random Forest (100)        1.000000         0.8875  1.000000  0.866056\n",
       "1       AdaBoost (100)        0.834246         0.8250  0.820863  0.815803"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a table of results \n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nSummary of All Models:\")\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5ec9f1",
   "metadata": {},
   "source": [
    "### Section 7. Conclusions and Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5efec",
   "metadata": {},
   "source": [
    "From the list of available options, two types of ensemble models were utilized:  \n",
    "  \n",
    "Random Forest (100)   \n",
    "Multiple decision trees (100 in this case) train in parallel, and the predictions are averaged.\n",
    "  \n",
    "AdaBoost (100)  \n",
    "Models train sequentially, with each new tree correcting previous errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3034af",
   "metadata": {},
   "source": [
    "Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1293559",
   "metadata": {},
   "source": [
    "Test Accuracy: \n",
    "\n",
    "Random Forest 88.88; AdaBoost 82.50  \n",
    "Random Forest metric is higher, so has slighly better accuracy.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4550cb76",
   "metadata": {},
   "source": [
    "Test F1 Score:  \n",
    "Random Forest 86.61; AdaBoost 81.58  \n",
    "Random Forest metric is higher, so performs slightly better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd7715",
   "metadata": {},
   "source": [
    "Confusion Matrix:  \n",
    "True positives:  Random Forest 0, 256, 28; AdaBoost 1, 240 23  \n",
    "Although the models are similar for the low class, Random Forest has more true positives for medium and high class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5487d26",
   "metadata": {},
   "source": [
    "Summary  \n",
    "  \n",
    "Based on the above metrics, Random Forest had slighly higher performance of the 2 models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
